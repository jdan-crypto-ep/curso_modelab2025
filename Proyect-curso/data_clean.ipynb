{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c070187d",
   "metadata": {},
   "source": [
    "# Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1644026a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando NO.xlsx...\n",
      "✓ NO.xlsx procesado exitosamente\n",
      "  - Filas originales: 8776\n",
      "  - Filas en formato largo: 307160\n",
      "  - Estaciones encontradas: 35\n",
      "Procesando NO2.xlsx...\n",
      "✓ NO2.xlsx procesado exitosamente\n",
      "  - Filas originales: 8776\n",
      "  - Filas en formato largo: 315936\n",
      "  - Estaciones encontradas: 36\n",
      "Procesando NOX.xlsx...\n",
      "✓ NOX.xlsx procesado exitosamente\n",
      "  - Filas originales: 8776\n",
      "  - Filas en formato largo: 307160\n",
      "  - Estaciones encontradas: 35\n",
      "Procesando Ozono.xlsx...\n",
      "✓ Ozono.xlsx procesado exitosamente\n",
      "  - Filas originales: 8776\n",
      "  - Filas en formato largo: 315936\n",
      "  - Estaciones encontradas: 36\n",
      "Procesando Temperature.xlsx...\n",
      "✓ Temperature.xlsx procesado exitosamente\n",
      "  - Filas originales: 8776\n",
      "  - Filas en formato largo: 245728\n",
      "  - Estaciones encontradas: 28\n",
      "Convirtiendo a formato ancho con contaminantes como columnas...\n",
      "\n",
      "✓ Procesamiento completado!\n",
      "✓ Archivo guardado como: datos_calidad_aire_procesados.xlsx\n",
      "✓ Total de registros: 240,684\n",
      "✓ Rango de fechas: 2024-01-01 00:00:00 a 2025-01-01 00:00:00\n",
      "✓ Contaminantes (columnas): NO, NO2, NOX, OZONO, TEMPERATURE\n",
      "✓ Estaciones: AJM, AJU, ATI, BJU, CAM, CCA, CHO, CUA, CUT, FAC, FAR, GAM, HGM, INN, IZT, LPR, MER, MGH, MON, MPA, NEZ, PED, SAC, SAG, TAH, TLA, TLI, UIZ, VIF, XAL, LLA, UAX, LAA, ACO\n",
      "\n",
      "Calculando medias móviles de 8 horas...\n",
      "Contaminantes encontrados: NO, NO2, NOX, OZONO, TEMPERATURE\n",
      "Procesando estación: AJM\n",
      "Procesando estación: AJU\n",
      "Procesando estación: ATI\n",
      "Procesando estación: BJU\n",
      "Procesando estación: CAM\n",
      "Procesando estación: CCA\n",
      "Procesando estación: CHO\n",
      "Procesando estación: CUA\n",
      "Procesando estación: CUT\n",
      "Procesando estación: FAC\n",
      "Procesando estación: FAR\n",
      "Procesando estación: GAM\n",
      "Procesando estación: HGM\n",
      "Procesando estación: INN\n",
      "Procesando estación: IZT\n",
      "Procesando estación: LPR\n",
      "Procesando estación: MER\n",
      "Procesando estación: MGH\n",
      "Procesando estación: MON\n",
      "Procesando estación: MPA\n",
      "Procesando estación: NEZ\n",
      "Procesando estación: PED\n",
      "Procesando estación: SAC\n",
      "Procesando estación: SAG\n",
      "Procesando estación: TAH\n",
      "Procesando estación: TLA\n",
      "Procesando estación: TLI\n",
      "Procesando estación: UIZ\n",
      "Procesando estación: VIF\n",
      "Procesando estación: XAL\n",
      "Procesando estación: LLA\n",
      "Procesando estación: UAX\n",
      "Procesando estación: LAA\n",
      "Procesando estación: ACO\n",
      "✓ Medias móviles calculadas: 240,462 registros\n",
      "✓ Columnas de medias móviles: NO_MEDIA_8H, NO2_MEDIA_8H, NOX_MEDIA_8H, OZONO_MEDIA_8H, TEMPERATURE_MEDIA_8H\n",
      "✓ Máximos diarios de ozono: 9,985 registros\n",
      "✓ Medias móviles guardadas en: datos_media_movil_8h.xlsx\n",
      "✓ Ozono máximo diario guardado en: ozono_maximo_diario.xlsx\n",
      "\n",
      "============================================================\n",
      "RESUMEN DE DATOS\n",
      "============================================================\n",
      "\n",
      "DATOS ORIGINALES:\n",
      "Total de registros: 240,684\n",
      "Contaminantes (columnas): NO, NO2, NOX, OZONO, TEMPERATURE\n",
      "\n",
      "Conteo por estación:\n",
      "ESTACION\n",
      "AJU    8356\n",
      "AJM    8311\n",
      "CUT    8304\n",
      "NEZ    8297\n",
      "MGH    8252\n",
      "GAM    8206\n",
      "FAC    8196\n",
      "CCA    8095\n",
      "IZT    8091\n",
      "TLI    8063\n",
      "MER    7992\n",
      "SAG    7976\n",
      "UIZ    7827\n",
      "MON    7823\n",
      "PED    7812\n",
      "CUA    7696\n",
      "BJU    7527\n",
      "SAC    7383\n",
      "INN    7343\n",
      "VIF    7238\n",
      "LPR    7171\n",
      "FAR    7110\n",
      "TLA    7093\n",
      "HGM    6889\n",
      "LLA    6801\n",
      "ATI    6780\n",
      "MPA    6719\n",
      "CAM    6264\n",
      "XAL    6015\n",
      "UAX    5965\n",
      "TAH    5881\n",
      "CHO    5229\n",
      "LAA    2799\n",
      "ACO    1180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadísticas por contaminante:\n",
      "\n",
      "NO:\n",
      "  - Registros totales: 240,684\n",
      "  - Registros válidos: 154,842\n",
      "  - Valores faltantes: 85,842\n",
      "  - Promedio: 13.76\n",
      "  - Mínimo: 0.00\n",
      "  - Máximo: 498.00\n",
      "\n",
      "NO2:\n",
      "  - Registros totales: 240,684\n",
      "  - Registros válidos: 176,477\n",
      "  - Valores faltantes: 64,207\n",
      "  - Promedio: 23.45\n",
      "  - Mínimo: 0.00\n",
      "  - Máximo: 140.00\n",
      "\n",
      "NOX:\n",
      "  - Registros totales: 240,684\n",
      "  - Registros válidos: 154,842\n",
      "  - Valores faltantes: 85,842\n",
      "  - Promedio: 37.29\n",
      "  - Mínimo: 0.00\n",
      "  - Máximo: 569.00\n",
      "\n",
      "OZONO:\n",
      "  - Registros totales: 240,684\n",
      "  - Registros válidos: 215,518\n",
      "  - Valores faltantes: 25,166\n",
      "  - Promedio: 33.03\n",
      "  - Mínimo: 0.00\n",
      "  - Máximo: 187.00\n",
      "\n",
      "TEMPERATURE:\n",
      "  - Registros totales: 240,684\n",
      "  - Registros válidos: 120,170\n",
      "  - Valores faltantes: 120,514\n",
      "  - Promedio: 17.37\n",
      "  - Mínimo: -3.90\n",
      "  - Máximo: 36.00\n",
      "\n",
      "MEDIAS MÓVILES 8H:\n",
      "Total de registros: 240,462\n",
      "Medias móviles calculadas: NO_MEDIA_8H, NO2_MEDIA_8H, NOX_MEDIA_8H, OZONO_MEDIA_8H, TEMPERATURE_MEDIA_8H\n",
      "\n",
      "Conteo por estación (medias móviles):\n",
      "ESTACION\n",
      "AJU    8351\n",
      "AJM    8306\n",
      "CUT    8299\n",
      "NEZ    8289\n",
      "MGH    8244\n",
      "GAM    8198\n",
      "FAC    8191\n",
      "CCA    8090\n",
      "IZT    8086\n",
      "TLI    8058\n",
      "MER    7984\n",
      "SAG    7968\n",
      "UIZ    7819\n",
      "MON    7812\n",
      "PED    7803\n",
      "CUA    7691\n",
      "BJU    7522\n",
      "SAC    7375\n",
      "INN    7338\n",
      "VIF    7233\n",
      "LPR    7166\n",
      "FAR    7102\n",
      "TLA    7088\n",
      "HGM    6884\n",
      "LLA    6796\n",
      "ATI    6772\n",
      "MPA    6711\n",
      "CAM    6259\n",
      "XAL    6001\n",
      "UAX    5960\n",
      "TAH    5873\n",
      "CHO    5224\n",
      "LAA    2794\n",
      "ACO    1175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "OZONO MÁXIMO DIARIO:\n",
      "Total de registros: 9,985\n",
      "Conteo por estación:\n",
      "ESTACION\n",
      "AJU    362\n",
      "IZT    361\n",
      "MGH    361\n",
      "PED    359\n",
      "CCA    358\n",
      "AJM    357\n",
      "TLI    350\n",
      "CUA    347\n",
      "MER    345\n",
      "UIZ    345\n",
      "FAC    340\n",
      "LPR    330\n",
      "NEZ    328\n",
      "CUT    325\n",
      "MON    317\n",
      "TLA    311\n",
      "ATI    308\n",
      "VIF    308\n",
      "LLA    307\n",
      "SAC    306\n",
      "SAG    304\n",
      "INN    300\n",
      "HGM    298\n",
      "FAR    286\n",
      "CAM    284\n",
      "BJU    282\n",
      "UAX    270\n",
      "TAH    262\n",
      "XAL    256\n",
      "MPA    245\n",
      "CHO    239\n",
      "GAM    234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadísticas de ozono máximo diario:\n",
      "  - Promedio: 59.62\n",
      "  - Mediana: 57.38\n",
      "  - Mínimo: 3.00\n",
      "  - Máximo: 146.62\n",
      "\n",
      "============================================================\n",
      "\n",
      "✓ Datos originales también guardados como CSV: datos_calidad_aire_procesados.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def procesar_datos_calidad_aire(directorio_archivos, archivo_salida=\"datos_combinados.xlsx\"):\n",
    "    \"\"\"\n",
    "    Procesa múltiples archivos Excel de datos de calidad del aire:\n",
    "    - Limpia valores erróneos (-99)\n",
    "    - Combina fecha y hora\n",
    "    - Une todos los archivos\n",
    "    - Transforma de formato ancho a largo\n",
    "    \n",
    "    Args:\n",
    "        directorio_archivos (str): Ruta del directorio con los archivos Excel\n",
    "        archivo_salida (str): Nombre del archivo de salida\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de archivos a procesar\n",
    "    nombres_archivos = ['NO.xlsx', 'NO2.xlsx', 'NOX.xlsx', 'Ozono.xlsx', 'Temperature.xlsx']\n",
    "    \n",
    "    # Diccionario para almacenar los DataFrames procesados\n",
    "    dataframes_procesados = []\n",
    "    \n",
    "    for nombre_archivo in nombres_archivos:\n",
    "        ruta_archivo = Path(directorio_archivos) / nombre_archivo\n",
    "        \n",
    "        if not ruta_archivo.exists():\n",
    "            print(f\"Advertencia: No se encontró el archivo {nombre_archivo}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Procesando {nombre_archivo}...\")\n",
    "        \n",
    "        try:\n",
    "            # Leer el archivo Excel\n",
    "            df = pd.read_excel(ruta_archivo)\n",
    "            \n",
    "            # Verificar que existan las columnas necesarias\n",
    "            if 'FECHA' not in df.columns or 'HORA' not in df.columns:\n",
    "                print(f\"Error: {nombre_archivo} no tiene las columnas FECHA y/o HORA\")\n",
    "                continue\n",
    "            \n",
    "            # Limpiar valores erróneos (reemplazar -99 con NaN)\n",
    "            df_limpio = df.copy()\n",
    "            \n",
    "            # Identificar columnas de estaciones (todas excepto FECHA y HORA)\n",
    "            columnas_estaciones = [col for col in df.columns if col not in ['FECHA', 'HORA']]\n",
    "            \n",
    "            # Reemplazar valores erróneos en columnas de estaciones\n",
    "            for col in columnas_estaciones:\n",
    "                df_limpio[col] = df_limpio[col].replace(-99, np.nan)\n",
    "                # También puedes agregar otros valores erróneos si los hay\n",
    "                df_limpio[col] = df_limpio[col].replace([-999, -9999], np.nan)\n",
    "            \n",
    "            # Convertir FECHA a datetime si no lo está\n",
    "            df_limpio['FECHA'] = pd.to_datetime(df_limpio['FECHA'], format='%d/%m/%Y')\n",
    "            \n",
    "            # Crear datetime combinando fecha y hora\n",
    "            # Asumiendo que HORA va de 1 a 24, donde 24 = 00:00 del día siguiente\n",
    "            df_limpio['HORA_AJUSTADA'] = df_limpio['HORA'].copy()\n",
    "            df_limpio.loc[df_limpio['HORA'] == 1, 'HORA_AJUSTADA'] = 0\n",
    "            \n",
    "            # Crear la columna datetime\n",
    "            df_limpio['FECHA_HORA'] = df_limpio['FECHA'] + pd.to_timedelta(df_limpio['HORA_AJUSTADA'], unit='h')\n",
    "            \n",
    "            \n",
    "            # Transformar a formato largo\n",
    "            # Primero, seleccionar las columnas relevantes\n",
    "            columnas_para_melt = ['FECHA_HORA'] + columnas_estaciones\n",
    "            df_subset = df_limpio[columnas_para_melt].copy()\n",
    "            \n",
    "            # Convertir a formato largo\n",
    "            df_largo = pd.melt(\n",
    "                df_subset,\n",
    "                id_vars=['FECHA_HORA'],\n",
    "                value_vars=columnas_estaciones,\n",
    "                var_name='ESTACION',\n",
    "                value_name='VALOR'\n",
    "            )\n",
    "            \n",
    "            # Agregar columna con el tipo de contaminante\n",
    "            contaminante = nombre_archivo.replace('.xlsx', '').upper()\n",
    "            df_largo['CONTAMINANTE'] = contaminante\n",
    "            \n",
    "            # Eliminar filas con valores NaN si lo deseas\n",
    "            # df_largo = df_largo.dropna(subset=['VALOR'])\n",
    "            \n",
    "            dataframes_procesados.append(df_largo)\n",
    "            \n",
    "            print(f\"✓ {nombre_archivo} procesado exitosamente\")\n",
    "            print(f\"  - Filas originales: {len(df)}\")\n",
    "            print(f\"  - Filas en formato largo: {len(df_largo)}\")\n",
    "            print(f\"  - Estaciones encontradas: {len(columnas_estaciones)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {nombre_archivo}: {str(e)}\")\n",
    "    \n",
    "    # Combinar todos los DataFrames\n",
    "    if dataframes_procesados:\n",
    "        df_combinado_largo = pd.concat(dataframes_procesados, ignore_index=True)\n",
    "        \n",
    "        # Convertir a formato ancho con cada contaminante como columna\n",
    "        print(\"Convirtiendo a formato ancho con contaminantes como columnas...\")\n",
    "        \n",
    "        df_final = df_combinado_largo.pivot_table(\n",
    "            index=['FECHA_HORA', 'ESTACION'],\n",
    "            columns='CONTAMINANTE',\n",
    "            values='VALOR',\n",
    "            aggfunc='first'  # En caso de duplicados, toma el primero\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Aplanar los nombres de columnas\n",
    "        df_final.columns.name = None\n",
    "        \n",
    "        # Reordenar columnas para que sea más legible\n",
    "        columnas_base = ['FECHA_HORA', 'ESTACION']\n",
    "        columnas_contaminantes = [col for col in df_final.columns if col not in columnas_base]\n",
    "        columnas_contaminantes.sort()  # Ordenar alfabéticamente\n",
    "        \n",
    "        df_final = df_final[columnas_base + columnas_contaminantes]\n",
    "        \n",
    "        # Ordenar por fecha y estación\n",
    "        df_final = df_final.sort_values(['FECHA_HORA', 'ESTACION'])\n",
    "        \n",
    "        # Resetear índice\n",
    "        df_final = df_final.reset_index(drop=True)\n",
    "        \n",
    "        # Guardar el archivo final\n",
    "        ruta_salida = Path(directorio_archivos) / archivo_salida\n",
    "        df_final.to_excel(ruta_salida, index=False)\n",
    "        \n",
    "        print(f\"\\n✓ Procesamiento completado!\")\n",
    "        print(f\"✓ Archivo guardado como: {ruta_salida}\")\n",
    "        print(f\"✓ Total de registros: {len(df_final):,}\")\n",
    "        print(f\"✓ Rango de fechas: {df_final['FECHA_HORA'].min()} a {df_final['FECHA_HORA'].max()}\")\n",
    "        print(f\"✓ Contaminantes (columnas): {', '.join(columnas_contaminantes)}\")\n",
    "        print(f\"✓ Estaciones: {', '.join(df_final['ESTACION'].unique())}\")\n",
    "        \n",
    "        return df_final\n",
    "    else:\n",
    "        print(\"No se procesaron archivos exitosamente.\")\n",
    "        return None\n",
    "\n",
    "def calcular_media_movil_8h(df):\n",
    "    \"\"\"\n",
    "    Calcula la media móvil de 8 horas para todos los contaminantes\n",
    "    y selecciona el máximo diario de ozono por estación\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con los datos en formato ancho (contaminantes como columnas)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df_media_movil, df_ozono_max_diario)\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    \n",
    "    print(\"\\nCalculando medias móviles de 8 horas...\")\n",
    "    \n",
    "    # Identificar columnas de contaminantes (todas excepto FECHA_HORA y ESTACION)\n",
    "    columnas_contaminantes = [col for col in df.columns if col not in ['FECHA_HORA', 'ESTACION']]\n",
    "    print(f\"Contaminantes encontrados: {', '.join(columnas_contaminantes)}\")\n",
    "    \n",
    "    # Crear lista para almacenar resultados\n",
    "    resultados_media_movil = []\n",
    "    resultados_ozono_max = []\n",
    "    \n",
    "    # Procesar cada estación por separado\n",
    "    for estacion in df['ESTACION'].unique():\n",
    "        print(f\"Procesando estación: {estacion}\")\n",
    "        \n",
    "        # Filtrar datos para esta estación\n",
    "        subset = df[df['ESTACION'] == estacion].copy()\n",
    "        \n",
    "        if len(subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Ordenar por fecha y hora\n",
    "        subset = subset.sort_values('FECHA_HORA')\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        \n",
    "        # Calcular medias móviles para cada contaminante\n",
    "        for contaminante in columnas_contaminantes:\n",
    "            if contaminante in subset.columns:\n",
    "                # Crear nombre de columna para la media móvil\n",
    "                nombre_media = f\"{contaminante}_MEDIA_8H\"\n",
    "                \n",
    "                # Calcular media móvil de 8 horas\n",
    "                subset[nombre_media] = subset[contaminante].rolling(\n",
    "                    window=8, \n",
    "                    min_periods=6,  # Al menos 6 valores válidos de 8 (75%)\n",
    "                    center=False\n",
    "                ).mean()\n",
    "        \n",
    "        # Agregar información de ventana para el registro\n",
    "        subset['HORA_INICIO_VENTANA'] = subset['FECHA_HORA']\n",
    "        subset['HORA_FIN_VENTANA'] = subset['FECHA_HORA'] + pd.Timedelta(hours=7)\n",
    "        \n",
    "        # Solo conservar registros que tengan al menos una media móvil válida\n",
    "        columnas_medias = [col for col in subset.columns if col.endswith('_MEDIA_8H')]\n",
    "        \n",
    "        # Crear una máscara para registros con al menos una media válida\n",
    "        mask_valido = subset[columnas_medias].notna().any(axis=1)\n",
    "        subset_valido = subset[mask_valido].copy()\n",
    "        \n",
    "        if len(subset_valido) > 0:\n",
    "            resultados_media_movil.append(subset_valido)\n",
    "            \n",
    "            # Para ozono, calcular máximo diario si existe\n",
    "            columna_ozono = None\n",
    "            for col in columnas_contaminantes:\n",
    "                if 'OZONO' in col.upper():\n",
    "                    columna_ozono = col\n",
    "                    break\n",
    "            \n",
    "            if columna_ozono is not None and f\"{columna_ozono}_MEDIA_8H\" in subset_valido.columns:\n",
    "                # Agregar columna de fecha (sin hora)\n",
    "                subset_valido['FECHA'] = subset_valido['FECHA_HORA'].dt.date\n",
    "                \n",
    "                # Encontrar el máximo diario por estación\n",
    "                ozono_col_media = f\"{columna_ozono}_MEDIA_8H\"\n",
    "                subset_ozono = subset_valido.dropna(subset=[ozono_col_media])\n",
    "                \n",
    "                if len(subset_ozono) > 0:\n",
    "                    ozono_max_diario = subset_ozono.loc[\n",
    "                        subset_ozono.groupby('FECHA')[ozono_col_media].idxmax()\n",
    "                    ].copy()\n",
    "                    \n",
    "                    # Renombrar la columna de ozono para simplicidad\n",
    "                    ozono_max_diario = ozono_max_diario.rename(columns={ozono_col_media: 'OZONO_MAXIMO_8H'})\n",
    "                    \n",
    "                    resultados_ozono_max.append(ozono_max_diario)\n",
    "    \n",
    "    # Combinar todos los resultados\n",
    "    df_media_movil = None\n",
    "    df_ozono_max_diario = None\n",
    "    \n",
    "    if resultados_media_movil:\n",
    "        df_media_movil = pd.concat(resultados_media_movil, ignore_index=True)\n",
    "        df_media_movil = df_media_movil.sort_values(['ESTACION', 'FECHA_HORA'])\n",
    "        \n",
    "        print(f\"✓ Medias móviles calculadas: {len(df_media_movil):,} registros\")\n",
    "        \n",
    "        # Mostrar columnas de medias móviles creadas\n",
    "        columnas_medias_creadas = [col for col in df_media_movil.columns if col.endswith('_MEDIA_8H')]\n",
    "        print(f\"✓ Columnas de medias móviles: {', '.join(columnas_medias_creadas)}\")\n",
    "    \n",
    "    if resultados_ozono_max:\n",
    "        df_ozono_max_diario = pd.concat(resultados_ozono_max, ignore_index=True)\n",
    "        df_ozono_max_diario = df_ozono_max_diario.sort_values(['ESTACION', 'FECHA'])\n",
    "        \n",
    "        print(f\"✓ Máximos diarios de ozono: {len(df_ozono_max_diario):,} registros\")\n",
    "    \n",
    "    return df_media_movil, df_ozono_max_diario\n",
    "\n",
    "def mostrar_resumen_datos(df, df_media_movil=None, df_ozono_max=None):\n",
    "    \"\"\"\n",
    "    Muestra un resumen estadístico de los datos procesados\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESUMEN DE DATOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Identificar columnas de contaminantes\n",
    "    columnas_contaminantes = [col for col in df.columns if col not in ['FECHA_HORA', 'ESTACION']]\n",
    "    \n",
    "    # Resumen datos originales\n",
    "    print(\"\\nDATOS ORIGINALES:\")\n",
    "    print(f\"Total de registros: {len(df):,}\")\n",
    "    print(f\"Contaminantes (columnas): {', '.join(columnas_contaminantes)}\")\n",
    "    \n",
    "    print(\"\\nConteo por estación:\")\n",
    "    print(df['ESTACION'].value_counts())\n",
    "    \n",
    "    # Estadísticas por contaminante\n",
    "    print(\"\\nEstadísticas por contaminante:\")\n",
    "    for contaminante in columnas_contaminantes:\n",
    "        if contaminante in df.columns:\n",
    "            valores = df[contaminante]\n",
    "            print(f\"\\n{contaminante}:\")\n",
    "            print(f\"  - Registros totales: {len(valores):,}\")\n",
    "            print(f\"  - Registros válidos: {valores.count():,}\")\n",
    "            print(f\"  - Valores faltantes: {valores.isna().sum():,}\")\n",
    "            if valores.count() > 0:\n",
    "                print(f\"  - Promedio: {valores.mean():.2f}\")\n",
    "                print(f\"  - Mínimo: {valores.min():.2f}\")\n",
    "                print(f\"  - Máximo: {valores.max():.2f}\")\n",
    "    \n",
    "    # Resumen medias móviles\n",
    "    if df_media_movil is not None:\n",
    "        print(f\"\\nMEDIAS MÓVILES 8H:\")\n",
    "        print(f\"Total de registros: {len(df_media_movil):,}\")\n",
    "        \n",
    "        # Identificar columnas de medias móviles\n",
    "        columnas_medias = [col for col in df_media_movil.columns if col.endswith('_MEDIA_8H')]\n",
    "        print(f\"Medias móviles calculadas: {', '.join(columnas_medias)}\")\n",
    "        \n",
    "        print(\"\\nConteo por estación (medias móviles):\")\n",
    "        print(df_media_movil['ESTACION'].value_counts())\n",
    "    \n",
    "    # Resumen ozono máximo diario\n",
    "    if df_ozono_max is not None:\n",
    "        print(f\"\\nOZONO MÁXIMO DIARIO:\")\n",
    "        print(f\"Total de registros: {len(df_ozono_max):,}\")\n",
    "        print(\"Conteo por estación:\")\n",
    "        print(df_ozono_max['ESTACION'].value_counts())\n",
    "        \n",
    "        # Estadísticas de ozono\n",
    "        if 'OZONO_MAXIMO_8H' in df_ozono_max.columns:\n",
    "            ozono_stats = df_ozono_max['OZONO_MAXIMO_8H'].describe()\n",
    "            print(f\"\\nEstadísticas de ozono máximo diario:\")\n",
    "            print(f\"  - Promedio: {ozono_stats['mean']:.2f}\")\n",
    "            print(f\"  - Mediana: {ozono_stats['50%']:.2f}\")\n",
    "            print(f\"  - Mínimo: {ozono_stats['min']:.2f}\")\n",
    "            print(f\"  - Máximo: {ozono_stats['max']:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Especifica la ruta donde están tus archivos Excel\n",
    "    directorio_archivos = \".\"  # Cambia esto por tu ruta\n",
    "    \n",
    "    # Procesar los datos básicos\n",
    "    datos_procesados = procesar_datos_calidad_aire(\n",
    "        directorio_archivos=directorio_archivos,\n",
    "        archivo_salida=\"datos_calidad_aire_procesados.xlsx\"\n",
    "    )\n",
    "    \n",
    "    if datos_procesados is not None:\n",
    "        # Calcular medias móviles de 8 horas\n",
    "        datos_media_movil, ozono_max_diario = calcular_media_movil_8h(datos_procesados)\n",
    "        \n",
    "        # Guardar archivos adicionales\n",
    "        if datos_media_movil is not None:\n",
    "            ruta_media_movil = Path(directorio_archivos) / \"datos_media_movil_8h.xlsx\"\n",
    "            datos_media_movil.to_excel(ruta_media_movil, index=False)\n",
    "            print(f\"✓ Medias móviles guardadas en: {ruta_media_movil}\")\n",
    "            \n",
    "            # También en CSV\n",
    "            ruta_media_movil_csv = Path(directorio_archivos) / \"datos_media_movil_8h.csv\"\n",
    "            datos_media_movil.to_csv(ruta_media_movil_csv, index=False)\n",
    "        \n",
    "        if ozono_max_diario is not None:\n",
    "            ruta_ozono_max = Path(directorio_archivos) / \"ozono_maximo_diario.xlsx\"\n",
    "            ozono_max_diario.to_excel(ruta_ozono_max, index=False)\n",
    "            print(f\"✓ Ozono máximo diario guardado en: {ruta_ozono_max}\")\n",
    "            \n",
    "            # También en CSV\n",
    "            ruta_ozono_max_csv = Path(directorio_archivos) / \"ozono_maximo_diario.csv\"\n",
    "            ozono_max_diario.to_csv(ruta_ozono_max_csv, index=False)\n",
    "        \n",
    "        # Mostrar resumen completo\n",
    "        mostrar_resumen_datos(datos_procesados, datos_media_movil, ozono_max_diario)\n",
    "        \n",
    "        # Guardar datos originales también como CSV\n",
    "        ruta_csv = Path(directorio_archivos) / \"datos_calidad_aire_procesados.csv\"\n",
    "        datos_procesados.to_csv(ruta_csv, index=False)\n",
    "        print(f\"\\n✓ Datos originales también guardados como CSV: {ruta_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
